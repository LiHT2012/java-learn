==== redis为什么不用多线程（不划算呗）
http://www.cainiaoxueyuan.com/sjk/1317.html

（1）纯内存操作；//绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的
时间复杂度都是O(1)；

2、数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的；

3、采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，
没有因为可能出现死锁而导致的性能消耗；//多线程仍然会有上下文切换的损耗，虽然比进程切换损耗小；

4、使用多路I/O复用模型，非阻塞IO；

5、使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；


==== 开源的，内存型数据存储系统，可以用作：数据库、缓存和消息中间件。
支持在服务器端计算集合的并，交和补集(difference)等，还支持多种排序功能。所以Redis也可以被看成是一个数据结构服务 器。
Redis的所有数据都是保存在内存中，然后不定期的通过异步方式保存到磁盘上(这称为“半持久化模式”)；也可以把每一次数据变化都写入到一个append only file(aof)里面
(这称为“全持久化模式”)。

它支持多种类型的数据结构，如字符串（Strings），散列（Hash），列表（List），集合（Set），有序集合（Sorted Set或者是ZSet）
与范围查询，Bitmaps，Hyperloglogs 和地理空间（Geospatial）索引半径查询。
其中常见的数据结构类型有：String、List、Set、Hash、ZSet这5种。


Redis 内置了复制（Replication），LUA脚本（Lua scripting）， LRU驱动事件（LRU eviction），事务（Transactions） 和
不同级别的磁盘持久化（Persistence），并通过 Redis哨兵（Sentinel）和自动分区（Cluster）提供高可用性（High Availability）。

Redis也提供了持久化的选项，这些选项可以让用户将自己的数据保存到磁盘上面进行存储。根据实际情况，可以每隔一定时间将数据集导出到
磁盘（快照），或者追加到命令日志中（AOF只追加文件），他会在执行写命令时，将被执行的写命令复制到硬盘里面。
也可以关闭持久化功能，将Redis作为一个高效的网络的缓存数据功能使用。

数据库的工作模式按存储方式可分为：硬盘数据库和内存数据库。Redis 将数据储存在内存里面，读写数据的时候都不会受到硬盘 I/O 速度的限制
，所以速度极快。
硬盘数据库：内存存索引，硬盘存值；
内存数据库则在内存中直接存值。

Redis采用的是基于内存的采用的是单进程单线程模型的 KV 数据库，由C语言编写，官方提供的数据是可以达到100000+的QPS（每秒内查询次数）
。这个数据不比采用单进程多线程的同样基于内存的 KV 数据库 Memcached 差！

官方给的每秒查询次数：连接数少于七八千时，每秒超10万次；当连接数达6万时，会降到每秒4万多。

//多路 I/O 复用模型
多路I/O复用模型是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I/O 事件时，就从阻塞态中唤醒，
于是程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。

这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络 IO 的时间消耗），
且 Redis 在内存中操作数据的速度非常快，也就是说内存内的操作不会成为影响Redis性能的瓶颈，主要由以上几点造就了 Redis 具有很高的吞吐量.

redis 为什么是单线程的？
官方FAQ回答：，因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，
那就顺理成章地采用单线程的方案了（毕竟采用多线程会有很多麻烦！）
从Redis 4.0版本开始会支持多线程的方式，但是，只是在某一些操作上进行多线程的操作！
我们使用单线程的方式是无法发挥多核CPU 性能，不过我们可以通过在单机开多个Redis 实例来完善！

一直在强调的单线程，只是在处理我们的网络请求的时候只有一个线程来处理，一个正式的Redis Server运行的时候肯定是不止一个线程的，这里需要大家明确的注意一下！
例如Redis进行持久化的时候会以子进程或者子线程的方式执行（具体是子线程还是子进程待读者深入研究）。
ps -ef | grep redis-Server
ps -T -p 进程号 //ps命令的“-T”参数表示显示线程（Show threads, possibly with SPID column.）“SID”栏表示线程ID，而“CMD”栏则显示了线程名称。

----
==== 注意点

1、我们知道Redis是用”单线程-多路复用IO模型”来实现高性能的内存数据服务的，这种机制避免了使用锁，但是同时这种机制在进行sunion之类的比较耗时的命令时会使redis的并发下降。
因为是单一线程，所以同一时刻只有一个操作在进行，所以，耗时的命令会导致并发的下降，不只是读并发，写并发也会下降。而单一线程也只能用到一个CPU核心，所以可以在同一个多核的
服务器中，可以启动多个实例，组成master-master或者master-slave的形式，耗时的读命令可以完全在slave进行。

需要改的redis.conf项：

pidfile /var/run/redis/redis_6377.pid  #pidfile要加上端口号
port 6377  #这个是必须改的
logfile /var/log/redis/redis_6377.log #logfile的名称也加上端口号
dbfilename dump_6377.rdb  #rdbfile也加上端口号

2、“我们不能任由操作系统负载均衡，因为我们自己更了解自己的程序，所以，我们可以手动地为其分配CPU核，而不会过多地占用CPU，或是让我们关键进程和一堆别的进程挤在一起。”。
CPU 是一个重要的影响因素，由于是单线程模型，Redis 更喜欢大缓存快速 CPU， 而不是多核

在多核 CPU 服务器上面，Redis 的性能还依赖NUMA 配置和处理器绑定位置。最明显的影响是 redis-benchmark 会随机使用CPU内核。为了获得精准的结果，需要使用固定处理器工具（
在 Linux 上可以使用 taskset）。最有效的办法是将客户端和服务端分离到两个不同的 CPU 来高校使用三级缓存。
七、扩展

以下也是你应该知道的几种模型，祝你的面试一臂之力！

1、单进程多线程模型：MySQL、Memcached、Oracle（Windows版本）；

2、多进程模型：Oracle（Linux版本）；

3、Nginx有两类进程，一类称为Master进程(相当于管理进程)，另一类称为Worker进程（实际工作进程）。启动方式有两种：

（1）单进程启动：此时系统中仅有一个进程，该进程既充当Master进程的角色，也充当Worker进程的角色。

（2）多进程启动：此时系统有且仅有一个Master进程，至少有一个Worker进程工作。

（3）Master进程主要进行一些全局性的初始化工作和管理Worker的工作；事件处理是在Worker中进行的。
----

==== redis持久化

https://www.cnblogs.com/chenliangcl/p/7240350.html

由于Redis的数据都存放在内存中，如果没有配置持久化，redis重启后数据就全丢失了，于是需要开启redis的持久化功能，将数据保存到磁盘上，当redis重启后，可以从磁盘中恢复数据。
redis提供两种方式进行持久化，一种是RDB持久化（原理是将Reids在内存中的数据库记录定时dump到磁盘上的RDB持久化），另外一种是AOF（append only file）持久化
（原理是将Reids的操作日志以追加的方式写入文件）
二者的区别

RDB持久化是指在指定的时间间隔内将内存中的数据集快照写入磁盘，实际操作过程是fork一个子进程，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储。

AOF持久化以日志的形式记录服务器所处理的每一个写、删除操作，查询操作不会记录，以文本的方式记录，可以打开文件看到详细的操作记录。


二者优缺点

RDB存在哪些优势呢？

1). 一旦采用该方式，那么你的整个Redis数据库将只包含一个文件，这对于文件备份而言是非常完美的。比如，你可能打算每个小时归档一次最近24小时的数据，同时还要每天归档一次
最近30天的数据。通过这样的备份策略，一旦系统出现灾难性故障，我们可以非常容易的进行恢复。

2). 对于灾难恢复而言，RDB是非常不错的选择。因为我们可以非常轻松的将一个单独的文件压缩后再转移到其它存储介质上。

3). 性能最大化。对于Redis的服务进程而言，在开始持久化时，它唯一需要做的只是fork出子进程，之后再由子进程完成这些持久化的工作，这样就可以极大的避免服务进程执行IO操作了。

4). 相比于AOF机制，如果数据集很大，RDB的启动效率会更高。

RDB又存在哪些劣势呢？

1). 如果你想保证数据的高可用性，即最大限度的避免数据丢失，那么RDB将不是一个很好的选择。因为系统一旦在定时持久化之前出现宕机现象，此前没有来得及写入磁盘的数据都将丢失。

2). 由于RDB是通过fork子进程来协助完成数据持久化工作的，因此，如果当数据集较大时，可能会导致整个服务器停止服务几百毫秒，甚至是1秒钟。
AOF的优势有哪些呢？

1). 该机制可以带来更高的数据安全性，即数据持久性。Redis中提供了3中同步策略，即每秒同步、每修改同步和不同步。事实上，每秒同步也是异步完成的，其效率也是非常高的，所差的是
一旦系统出现宕机现象，那么这一秒钟之内修改的数据将会丢失。而每修改同步，我们可以将其视为同步持久化，即每次发生的数据变化都会被立即记录到磁盘中。可以预见，这种方式在效率上
是最低的。至于无同步，无需多言，我想大家都能正确的理解它。

2). 由于该机制对日志文件的写入操作采用的是append模式，因此在写入过程中即使出现宕机现象，也不会破坏日志文件中已经存在的内容。然而如果我们本次操作只是写入了一半数据就出现了
系统崩溃问题，不用担心，在Redis下一次启动之前，我们可以通过redis-check-aof工具来帮助我们解决数据一致性的问题。

3). 如果日志过大，Redis可以自动启用rewrite机制。即Redis以append模式不断的将修改数据写入到老的磁盘文件中，同时Redis还会创建一个新的文件用于记录此期间有哪些修改命令被
执行。因此在进行rewrite切换时可以更好的保证数据安全性。

4). AOF包含一个格式清晰、易于理解的日志文件用于记录所有的修改操作。事实上，我们也可以通过该文件完成数据的重建。

AOF的劣势有哪些呢？

1). 对于相同数量的数据集而言，AOF文件通常要大于RDB文件。RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。

2). 根据同步策略的不同，AOF在运行效率上往往会慢于RDB。总之，每秒同步策略的效率是比较高的，同步禁用策略的效率和RDB一样高效。

二者选择的标准，就是看系统是愿意牺牲一些性能，换取更高的缓存一致性（aof），还是愿意写操作频繁的时候，不启用备份来换取更高的性能，待手动运行save的时候，再做备份（rdb）。
rdb这个就更有些 eventually consistent的意思了。

4、常用配置
RDB持久化配置

Redis会将数据集的快照dump到dump.rdb文件中。此外，我们也可以通过配置文件来修改Redis服务器dump快照的频率，在打开redis.conf文件之后，我们搜索save，可以看到下面的配置信息：

save 900 1              #在900秒(15分钟)之后，如果至少有1个key发生变化，则dump内存快照。

save 300 10            #在300秒(5分钟)之后，如果至少有10个key发生变化，则dump内存快照。

save 60 10000        #在60秒(1分钟)之后，如果至少有10000个key发生变化，则dump内存快照。
AOF持久化配置

在Redis的配置文件中存在三种同步方式，它们分别是：

appendfsync always     #每次有数据修改发生时都会写入AOF文件。

appendfsync everysec  #每秒钟同步一次，该策略为AOF的缺省策略。

appendfsync no          #从不同步。高效但是数据不会被持久化


==== 基本使用
https://www.cnblogs.com/donghaonan/p/10403781.html

1.安装redis 使用命令sudo apt-get install redis-server
　　whereis redis 查看redis的安装位置(猜想默认安装在/etc/redis目录下，或者ubuntu系统自带的在这个目录下)
　　ps -aux | grep redis 查看redis服务的进程运行
　　netstat -nlt | grep 6379根据redis运行的端口号查看redis服务器状态，端口号前是redis服务监听的IP(默认只有本机IP 127.0.0.1)
2.启动redis
　　本地启动 redis-cli
　　远程连接(需要本地安装redis客户端) redis-cli -h host(远程ip) -p port(端口号) -a password(密码)

修改以支持后台启动
sudo vim redis.conf
# i
# 修改其中的daemonize 从no 变成 yes
# daemonize no -> daemonize yes

# 在redis安装目录的根目录下
# 启动redis
./bin/redis-server ./redis.conf &  （&表示后台启动，则不会停留在redis界面，此时的ctrl+c不会将其停止掉）
# 启动客户端
./bin/redis-cli
# 这样直接操作的都是内存，不是数据库，数据库会慢半拍
# 测试数据库(redis)是否连通
# 除了我们通过set key value，get key的方式可以测试
# 还可以ping，证明连通了
127.0.0.1:6379> ping
PONG

==== redis的内存回收策略

1、maxmemory-policy noeviction（默认）：内存空间不足会报错

2、allkeys-lru：最少使用的数据去淘汰

3、allkeys-random：随机淘汰一些key

4、volatile-random：在已经设置了过期的时间去随机淘汰

     volatile-lru：在已经设置了过期的时间去淘汰最少使用的数据

     volatile-ttl：在已经设置了过期的时间去淘汰即将过期的key


3.redis的配置(在本地连接上之后，如 redis-cli -p 3333)
　　config get * 查看redis的所有配置参数
　　config get (name) 查看redis某个配置参数
　　config set (name) (value) 修改redis的某些配置(有些配置的修改不支持该操作，例如修改bind)
　　不支持客户端修改的操作需要修改redis的配置文件 sudo vi /etc/redis/redis.conf
　　　　例如：修改配置文件redis.conf配置远程访问
　　　　　　   (1)在配置文件中查找 bind 127.0.0.1 将其注释 改为 #bind 127.0.0.1
　　　　    　   (2)重新启动redis即可
{

  基本使用：
  　　　　del key 用于删除存在的key
  　　　　keys pattern 查看所有符合模式匹配的key
  　　　　　　例如 keys * 查看所有key
  　　　　exists key 查看key是否存在
  　　　　type key 查看key的存储类型
  　　　　rename key newkey 修改key的名称
  　　redis中主要包含5中数据类型字符串(String)、哈希(Hash)、列表(list)、集合(Set)、有序集合(Sorted set)
  　　(1)字符串(String)类型主要操作
  　　　　set key value 为指定key设置值
  　　　　get key 获取指定key的值
  　　　　getrange key start end 获取指定key值得子串 start <= 字串 <= end
  　　　　mget key1 key2 ... 获取所有给定的key值
  　　　　strlen key 返回key所存储的字符串值得长度
  　　　　append key value 如果key已经存在并且是一个字符串，append将指定的value追加到该key原来值得末尾，否则添加一个新key 值为value
  　　(2)哈希(Hash)类型的主要操作
  　　　　hmset key field1 value1 field2 value2 ... 将多个field-value(域-值)对设置到哈希表key中
  　　　　hmget key field1 field2 ... 获取所有给定字段的值
  　　　　hdel key field1 field2 ... 删除一个或多个字段
  　　　　hexists key field 查看哈希表key中，指定字段是否存在
  　　　　hget key field 获取存储在哈希表key中指定字段的值
  　　　　hset key field value 将key中字段值设置为value
  　　　　hgetall key 获取哈希表key中所有字段和值
  　　　　hkeys key 获取所有哈希表key中字段
  　　　　hvals key 获取哈希表中所有值
  　　　　hlen key 获取哈希表key中字段的数量

  　　(3)列表类型(list)的主要操作
  　　　　lpush key value1 value2 ... 将一个或多个值插入到列表头部
  　　　　rpush key value1 value2 ... 将一个或多个值插入到列表尾部
  　　　　lpop key 移除并获取列表的第一个元素
  　　　　rpop key 移除并获取列表的最后一个元素
  　　　　lindex key index 通过索引获取列表中元素
  　　　　linsert key before | after pivot value 在列表元素pivot 前或者后插入元素value
  　　　　llen key 获取列表长度
  　　　　lrange key start end 获取列表指定范围内元素
  　　　　lrem key count value 移除列表元素
  　　　　　　备注：
  　　　　　　　　count > 0 : 从表头开始向表尾搜索，移除与 VALUE 相等的元素，数量为 COUNT 。
  　　　　　　　　count < 0 : 从表尾开始向表头搜索，移除与 VALUE 相等的元素，数量为 COUNT 的绝对值。
  　　　　　　　　count = 0 : 移除表中所有与 VALUE 相等的值。
  　　　　lset key index value 通过索引设置列表元素的值
  　　　　ltrim key start end 让列表保留区间 start end范围内的元素，其他元素删除

  　　(4)集合类型(set)的主要操作
  　　　　sadd key member1 member2 ... 向集合添加一个或多个成员
  　　　　scard key 获取集合的成员数
  　　　　sdiff key1 key2 获取集合的差集 返回key1 中有， key2 中没有的，与前后顺序有关
  　　　　sinter key1 key2 获取key1 和 key2 的交集
  　　　　sismember key member 判断member 是否是key中成员
  　　　　smembers key 返回key中所有成员
  　　　　spop key 移除并返回key中的一个随机元素
  　　　　srandmember key [count] 返回key中一个或多个随机数 count值设置返回随机数
  　　　　srem key member1 member2 ... 移除集合中一个或多个成员
  　　　　sscan key cursor match [pattern] [COUNT count] 迭代集合中的元素
  　　　　　　备注：
  　　　　　　　　cursor 扫描开始的位置 0 1 等
  　　　　　　　　match pattern 正则匹配用来进行过滤
  　　　　　　　　cout 扫描个数

  　　(5)有序集合(sorted set)类型的主要操作
  　　　　zadd key score1 member1 score2 member2 ... 向有序集合中添加一个或多个成员，或者更新已存在成员的分数
  　　　　zcard key 获取有序集合的成员数
  　　　　zcount key min max 计算在有序集合中指定区间分数的成员数
  　　　　zrange key start end 通过索引区间返回有序集合指定区间内的成员
  　　　　zrank key member 返回有序集合中指定成员的索引
  　　　　zrem key member1 member2 ... 移除有序集合中一个或多个成员
  　　　　zrevrange key start end 返回有序集合中指定区间内的成员，通过索引，分数从高到底
  　　　　zrevrank key member 返回有序集合中指定成员的排名，有序集合按分数从大到小排列
  　　　　zscore key member 返回有序集合中成员分数值
　　　　zscan key cursor [match pattern] [count] 迭代有序集合中的元素（包括元素成员和元素分值）
}
